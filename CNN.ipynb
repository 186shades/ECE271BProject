{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfac333",
   "metadata": {},
   "source": [
    "# ECE 271B Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4eaf7",
   "metadata": {},
   "source": [
    "## GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8cdc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddd154",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from APINet.models import API_Net "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1203a",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77dc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, config, csv_path, checkpoint_dir=None):\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=0.00002)\n",
    "\n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n",
    "    # should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    dataloaders = {'train': DataLoader(dataset['train'], batch_size=config[\"batch_size_train\"],\n",
    "                    shuffle=True, drop_last = True, num_workers=8),\n",
    "                   'val': DataLoader(dataset['val'], batch_size=config[\"batch_size_val\"],\n",
    "                    shuffle=True, drop_last = True, num_workers=8),}\n",
    "    \n",
    "    acc_train, acc_val, loss_train, loss_val = [], [], [], []\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(config[\"epoch\"]):\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            total, epoch = 0, 0\n",
    "            running_loss, running_corrects = 0.0, 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss = running_loss / total\n",
    "                train_acc = running_corrects / total\n",
    "                acc_train.append(train_acc)\n",
    "                loss_train.append(train_loss)\n",
    "            elif phase == 'val':\n",
    "                val_loss = running_loss / total\n",
    "                val_acc = running_corrects / total\n",
    "                acc_val.append(val_acc)\n",
    "                loss_val.append(val_loss)\n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                \n",
    "        print(f\"train_acc: {train_acc:.4f}\", f\"train_loss: {train_loss:.4f}\",\n",
    "              f\"val_acc: {val_acc:.4f}\", f\"{val_loss:.4f}\")\n",
    "\n",
    "        if checkpoint_dir and (epoch + 1) // 5 == 0:\n",
    "            path = os.path.join(checkpoint_dir, f\"checkpoint_{epoch+1}\")\n",
    "            torch.save(\n",
    "                (model.state_dict(), optimizer.state_dict()), path)\n",
    "            \n",
    "    record = pd.DataFrame(\n",
    "    {'train_loss': loss_train,\n",
    "     'train_acc': acc_train,\n",
    "     'val_loss': loss_val,\n",
    "     'val_acc': acc_val\n",
    "    })\n",
    "    record.to_csv(csv_path)\n",
    "    \n",
    "    return acc_train, acc_val, loss_train, loss_val, best_model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f319a",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123789a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataset):\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    dataloaders = DataLoader(dataset, batch_size=1,\n",
    "                    shuffle=False, drop_last = True, num_workers=8)\n",
    "    \n",
    "    acc_train, acc_val, loss_train, loss_val = [], [], [], []\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    total, epoch = 0, 0\n",
    "    running_loss, running_corrects = 0.0, 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        all_preds.append(preds.item())\n",
    "        all_labels.append(labels.item())\n",
    "        \n",
    "    acc = accuracy_score(all_preds, all_labels)\n",
    "    prec = f1_score(all_preds, all_labels)\n",
    "    f1 = precision_score(all_preds, all_labels)\n",
    "    rec = recall_score(all_preds, all_labels)\n",
    "\n",
    "    print(f\"val_acc: {acc:.4f}\", f\"val_loss: {running_loss/len(all_preds):.4f}\",\n",
    "          f'precision: {prec:.4f}', f'f1 score: {f1:.4f}', f'recall: {rec:.4f}')\n",
    "    \n",
    "    return\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526a545",
   "metadata": {},
   "source": [
    "## Model with non-augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "VGG = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
    "VGG.classifier[6] = nn.Linear(VGG.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa41484",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"img_size\": (128, 128), #768,\n",
    "    \"epoch\": 20,\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size_train\": 32,\n",
    "    \"batch_size_val\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55267607",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(config['img_size']),\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f84be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageFolder('./data_mhist/dataset/train', transform=transform)\n",
    "dataset_test = ImageFolder('./data_mhist/dataset/val', transform=transform)\n",
    "\n",
    "dataset = {\"train\": dataset_train, \"val\": dataset_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e01ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_train_res, acc_val_res, loss_train_res, loss_val_res, resnet = train(resnet, dataset, config, f'./log_resnet_noAug.csv')\n",
    "torch.save(resnet.state_dict(), f'./resnet_noAug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bf240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_train_vgg, acc_val_vgg, loss_train_vgg, loss_val_vgg, VGG = train(VGG, dataset, config, f'./log_VGG_noAug.csv')\n",
    "torch.save(VGG.state_dict(), f'./vgg_noAug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4afb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.load_state_dict(torch.load(f'./resnet_noAug.pt'))\n",
    "VGG.load_state_dict(torch.load(f'./vgg_noAug.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(resnet, dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(VGG, dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in resnet.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab3052",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base = resnet18()\n",
    "VGG_base = vgg16()\n",
    "\n",
    "resnet_base.fc = nn.Linear(resnet_base.fc.in_features, 2)\n",
    "VGG_base.classifier[6] = nn.Linear(VGG_base.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"img_size\": (128, 128), #768,\n",
    "    \"epoch\": 300,\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size_train\": 32,\n",
    "    \"batch_size_val\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(config['img_size']),\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d278281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageFolder('./data_mhist/dataset/train', transform=transform)\n",
    "dataset_test = ImageFolder('./data_mhist/dataset/val', transform=transform)\n",
    "\n",
    "dataset = {\"train\": dataset_train, \"val\": dataset_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_res_base, acc_val_res_base, loss_train_res_base, loss_val_res_base, resnet_base = train(resnet_base, dataset, config, f'./log_resnet_noAug_base.csv')\n",
    "torch.save(resnet_base.state_dict(), f'./resnet_noAug_base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_vgg_base, acc_val_vgg_base, loss_train_vgg_base, loss_val_vgg_base, VGG = train(VGG_base, dataset, config, f'./log_VGG_noAug_base.csv')\n",
    "torch.save(VGG_base.state_dict(), f'./vgg_noAug_base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base.load_state_dict(torch.load(f'./resnet_noAug_base.pt'))\n",
    "VGG_base.load_state_dict(torch.load(f'./vgg_noAug_base.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3606b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(resnet_base, dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa073f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(VGG_base, dataset['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30256d2",
   "metadata": {},
   "source": [
    "## Baseline model with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base_aug = resnet18()\n",
    "VGG_base_aug = vgg16()\n",
    "\n",
    "resnet_base_aug.fc = nn.Linear(resnet_base_aug.fc.in_features, 2)\n",
    "VGG_base_aug.classifier[6] = nn.Linear(VGG_base_aug.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"img_size\": (128, 128), #768,\n",
    "    \"epoch\": 5,\n",
    "    \"lr\": 0.00001,\n",
    "    \"batch_size_train\": 32,\n",
    "    \"batch_size_val\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug=transforms.Compose([\n",
    "    transforms.Resize(config['img_size']),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset_train = ImageFolder('./data_mhist/dataset/train', transform=transform_aug)\n",
    "aug_dataset_test = ImageFolder('./data_mhist/dataset/val', transform=transform)\n",
    "\n",
    "aug_dataset = {\"train\": aug_dataset_train, \"val\": aug_dataset_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca59beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_res_base_aug, acc_val_res_base_aug, loss_train_res_base_aug, loss_val_res_base_aug, resnet_base_aug = train(resnet_base_aug, aug_dataset, config, f'./log_resnet_base_aug.csv')\n",
    "torch.save(resnet_base_aug.state_dict(), f'./resnet_base_aug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a31e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_train_vgg_base_aug, acc_val_vgg_base_aug, loss_train_vgg_base_aug, loss_val_vgg_base_aug, VGG_base_aug = train(VGG_base_aug, aug_dataset, config, f'./log_VGG_base_aug.csv')\n",
    "torch.save(VGG_base_aug.state_dict(), f'./vgg_base_aug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base_aug.load_state_dict(torch.load(f'./resnet_base_aug.pt'))\n",
    "VGG_base_aug.load_state_dict(torch.load(f'./vgg_base_aug.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(resnet_base_aug, dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(VGG_base_aug, dataset['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e1eac",
   "metadata": {},
   "source": [
    "## Model with augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd947bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_aug = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "VGG_aug = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "resnet_aug.fc = nn.Linear(resnet_aug.fc.in_features, 2)\n",
    "VGG_aug.classifier[6] = nn.Linear(VGG_aug.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"img_size\": (128, 128), #768,\n",
    "    \"epoch\": 20,\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size_train\": 32,\n",
    "    \"batch_size_val\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug=transforms.Compose([\n",
    "    transforms.Resize(config['img_size']),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset_train = ImageFolder('./data_mhist/dataset/train', transform=transform_aug)\n",
    "aug_dataset_test = ImageFolder('./data_mhist/dataset/val', transform=transform)\n",
    "\n",
    "aug_dataset = {\"train\": aug_dataset_train, \"val\": aug_dataset_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6b9a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_train_res_aug, acc_val_res_aug, loss_train_res_aug, loss_val_res_aug, resnet_aug = train(resnet_aug, aug_dataset, config, f'./log_resnet_aug.csv')\n",
    "torch.save(resnet_aug.state_dict(), f'./resnet_aug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6beef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_train_vgg_aug, acc_val_vgg_aug, loss_train_vgg_aug, loss_val_vgg_aug, VGG_aug = train(VGG_aug, aug_dataset, config, f'./log_VGG_aug.csv')\n",
    "torch.save(VGG_aug.state_dict(), f'./vgg_aug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc829b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base_aug.load_state_dict(torch.load(f'./resnet_aug.pt'))\n",
    "VGG_base_aug.load_state_dict(torch.load(f'./vgg_aug.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdf0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(resnet_base_aug, dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8390f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(VGG_base_aug, dataset['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1bf55c",
   "metadata": {},
   "source": [
    "## Fine-grained model with non-augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_fg(scores, targets, k):\n",
    "    \"\"\"\n",
    "    Computes top-k accuracy, from predicted and true labels.\n",
    "\n",
    "    :param scores: scores from the model\n",
    "    :param targets: true labels\n",
    "    :param k: k in top-k accuracy\n",
    "    :return: top-k accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = targets.size(0)\n",
    "    _, ind = scores.topk(k, 1, True, True)\n",
    "    correct = ind.eq(targets.view(-1, 1).expand_as(ind))\n",
    "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
    "    return correct_total.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dff83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fine_grained(model, dataset, config, csv_path, checkpoint_dir=None):\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    rank_criterion = nn.MarginRankingLoss(margin=0.05)\n",
    "    softmax_layer = nn.Softmax(dim=1).to(device)\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=0.00002)\n",
    "\n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n",
    "    # should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    dataloaders = {'train': DataLoader(dataset['train'], batch_size=config[\"batch_size_train\"],\n",
    "                    shuffle=True, drop_last = True, num_workers=8),\n",
    "                   'val': DataLoader(dataset['val'], batch_size=config[\"batch_size_val\"],\n",
    "                    shuffle=True, drop_last = True, num_workers=8),}\n",
    "    \n",
    "    acc_train, acc_val, loss_train, loss_val = [], [], [], []\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(config[\"epoch\"]):\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            total, epoch = 0, 0\n",
    "            running_loss, running_corrects = 0.0, 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    logit1_self, logit1_other, logit2_self, logit2_other, labels1, labels2 = model(inputs, labels, flag='train')\n",
    "                    batch_size = logit1_self.shape[0]\n",
    "                    \n",
    "                    self_logits = torch.zeros(2*batch_size, 2).to(device) # 2 classes\n",
    "                    other_logits= torch.zeros(2*batch_size, 2).to(device)\n",
    "                    self_logits[:batch_size] = logit1_self\n",
    "                    self_logits[batch_size:] = logit2_self\n",
    "                    other_logits[:batch_size] = logit1_other\n",
    "                    other_logits[batch_size:] = logit2_other\n",
    "\n",
    "                    # compute loss\n",
    "                    logits = torch.cat([self_logits, other_logits], dim=0)\n",
    "                    targets = torch.cat([labels1, labels2, labels1, labels2], dim=0)\n",
    "                    softmax_loss = criterion(logits, targets)\n",
    "\n",
    "                    self_scores = softmax_layer(self_logits)[torch.arange(2*batch_size).to(device).long(),\n",
    "                                                                     torch.cat([labels1, labels2], dim=0)]\n",
    "                    other_scores = softmax_layer(other_logits)[torch.arange(2*batch_size).to(device).long(),\n",
    "                                                                     torch.cat([labels1, labels2], dim=0)]\n",
    "                    flag = torch.ones([2*batch_size, ]).to(device)\n",
    "                    rank_loss = rank_criterion(self_scores, other_scores, flag)\n",
    "\n",
    "                    loss = softmax_loss + rank_loss\n",
    "\n",
    "#                     _, preds = torch.max(logits, 1)\n",
    "                    total += targets.size(0)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += correct_fg(logits, targets, 1)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss = running_loss / total\n",
    "                train_acc = running_corrects / total\n",
    "                acc_train.append(train_acc)\n",
    "                loss_train.append(train_loss)\n",
    "            elif phase == 'val':\n",
    "                val_loss = running_loss / total\n",
    "                val_acc = running_corrects / total\n",
    "                acc_val.append(val_acc)\n",
    "                loss_val.append(val_loss)\n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                \n",
    "        print(f\"train_acc: {train_acc:.4f}\", f\"train_loss: {train_loss:.4f}\",\n",
    "              f\"val_acc: {val_acc:.4f}\", f\"{val_loss:.4f}\")\n",
    "\n",
    "        if checkpoint_dir and (epoch + 1) // 5 == 0:\n",
    "            path = os.path.join(checkpoint_dir, f\"checkpoint_{epoch+1}\")\n",
    "            torch.save(\n",
    "                (model.state_dict(), optimizer.state_dict()), path)\n",
    "            \n",
    "    record = pd.DataFrame(\n",
    "    {'train_loss': loss_train,\n",
    "     'train_acc': acc_train,\n",
    "     'val_loss': loss_val,\n",
    "     'val_acc': acc_val\n",
    "    })\n",
    "    record.to_csv(csv_path)\n",
    "    print(f'Best Acc: {best_acc}')\n",
    "    \n",
    "    return acc_train, acc_val, loss_train, loss_val, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6924089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fine_grained(model, dataset):\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    dataloaders = DataLoader(dataset, batch_size=1,\n",
    "                    shuffle=False, drop_last = True, num_workers=8)\n",
    "    \n",
    "    acc_train, acc_val, loss_train, loss_val = [], [], [], []\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    total, epoch = 0, 0\n",
    "    running_loss, running_corrects = 0.0, 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            logits = model(inputs, targets=None, flag='val')\n",
    "            logits = logits.unsqueeze(0)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total += logits.shape[0]\n",
    "            _, preds = torch.max(logits, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu())\n",
    "        all_labels.extend(labels.cpu())\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(logits == labels.data).item()\n",
    "                \n",
    "    acc = accuracy_score(all_preds, all_labels)\n",
    "    prec = f1_score(all_preds, all_labels)\n",
    "    f1 = precision_score(all_preds, all_labels)\n",
    "    rec = recall_score(all_preds, all_labels)\n",
    "\n",
    "    print(f\"val_acc: {acc:.4f}\", f\"val_loss: {running_loss/len(all_preds):.4f}\",\n",
    "          f'precision: {prec:.4f}', f'f1 score: {f1:.4f}', f'recall: {rec:.4f}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"img_size\": (512, 512), #768,\n",
    "    \"epoch\": 5,\n",
    "    \"lr\": 0.000001,\n",
    "    \"batch_size_train\": 8,\n",
    "    \"batch_size_val\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(config['img_size']),\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df10ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageFolder('./data_mhist/dataset/train', transform=transform)\n",
    "dataset_test = ImageFolder('./data_mhist/dataset/val', transform=transform)\n",
    "\n",
    "dataset = {\"train\": dataset_train, \"val\": dataset_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_net = API_Net()\n",
    "API_net.fc = nn.Linear(API_net.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b419d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_api, acc_val_api, loss_train_api, loss_val_api, API_net = train_fine_grained(API_net, dataset, config, f'./log_api_noaug.csv')\n",
    "torch.save(API_net.state_dict(), f'./api_noaug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug=transforms.Compose([\n",
    "    transforms.Resize(config['img_size']),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset_train = ImageFolder('./data_mhist/dataset/train', transform=transform_aug)\n",
    "aug_dataset_test = ImageFolder('./data_mhist/dataset/val', transform=transform)\n",
    "\n",
    "aug_dataset = {\"train\": aug_dataset_train, \"val\": aug_dataset_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_net_aug = API_Net()\n",
    "API_net_aug.fc = nn.Linear(API_net_aug.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0795a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_api_aug, acc_val_api_aug, loss_train_api_aug, loss_val_api_aug, API_net_aug = train_fine_grained(API_net_aug, aug_dataset, config, f'./log_api_aug.csv')\n",
    "torch.save(API_net_aug.state_dict(), f'./api_aug.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_net_aug.load_state_dict(torch.load(f'./api_aug.pt'))\n",
    "API_net.load_state_dict(torch.load(f'./api_noaug'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c369610",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fine_grained(API_net, dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fine_grained(API_net_aug, dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a89387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
